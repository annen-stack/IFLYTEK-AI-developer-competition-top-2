{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "* 此 notebook 用于训练 XGBoost 模型，模型结果保存在 ```Model``` 目录下\n",
    "* 此 notebook 基于上述模型对测试数据集进行预测，预测结果保存在 ```Output``` 目录下\n",
    "* 运行此 notebook 前，请确保已经正确运行前置程序 ```trainPrep.py``` 和 ```testPrep.py```，得到特征文件 ```train_data.csv``` 和 ```test_data.csv```，并确保它们和此程序位于同一目录下\n",
    "\n",
    "## 1. Preparation\n",
    "导入需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 取消warning\n",
    "\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data & Standardization\n",
    "读取数据，并使用 z-score 进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_ = pd.read_csv('train_data.csv')\n",
    "test_ = pd.read_csv('test_data.csv')\n",
    "# 填充缺失值\n",
    "train_ = train_.fillna(0)\n",
    "test_ = test_.fillna(0)\n",
    "# 定义标准化函数\n",
    "def standardization(df):\n",
    "    newDataFrame = pd.DataFrame(index=df.index)\n",
    "    columns = df.columns.tolist()\n",
    "    for c in columns:\n",
    "        if (c == 'label'):\n",
    "            newDataFrame[c] = df[c].tolist()\n",
    "        else:\n",
    "            d = df[c]\n",
    "            newDataFrame[c] = ((d - np.mean(d)) / (np.std(d))).tolist()\n",
    "    return newDataFrame\n",
    "# 进行标准化\n",
    "train_data = standardization(train_)\n",
    "test_data =  standardization(test_)\n",
    "# 提取特征和类别\n",
    "label = train_data['label'] # label 从 0 开始标记，0，1，2，3 分别表示 4 种情绪\n",
    "feature = train_data.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "训练 XGBoost 模型，并调整超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.55039\tval-merror:0.615584\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.488882\tval-merror:0.579221\n",
      "[2]\ttrain-merror:0.457118\tval-merror:0.594805\n",
      "[3]\ttrain-merror:0.435749\tval-merror:0.584416\n",
      "[4]\ttrain-merror:0.410049\tval-merror:0.563636\n",
      "[5]\ttrain-merror:0.40283\tval-merror:0.545455\n",
      "[6]\ttrain-merror:0.371643\tval-merror:0.524675\n",
      "[7]\ttrain-merror:0.359515\tval-merror:0.532468\n",
      "[8]\ttrain-merror:0.33497\tval-merror:0.527273\n",
      "[9]\ttrain-merror:0.321109\tval-merror:0.527273\n",
      "[10]\ttrain-merror:0.306671\tval-merror:0.511688\n",
      "[11]\ttrain-merror:0.29743\tval-merror:0.514286\n",
      "[12]\ttrain-merror:0.287323\tval-merror:0.519481\n",
      "[13]\ttrain-merror:0.27635\tval-merror:0.511688\n",
      "[14]\ttrain-merror:0.262489\tval-merror:0.532468\n",
      "[15]\ttrain-merror:0.251516\tval-merror:0.527273\n",
      "[16]\ttrain-merror:0.243431\tval-merror:0.527273\n",
      "[17]\ttrain-merror:0.235634\tval-merror:0.524675\n",
      "[18]\ttrain-merror:0.228415\tval-merror:0.535065\n",
      "[19]\ttrain-merror:0.226393\tval-merror:0.532468\n",
      "[20]\ttrain-merror:0.21542\tval-merror:0.524675\n",
      "[21]\ttrain-merror:0.202426\tval-merror:0.506494\n",
      "[22]\ttrain-merror:0.202137\tval-merror:0.514286\n",
      "[23]\ttrain-merror:0.19434\tval-merror:0.509091\n",
      "[24]\ttrain-merror:0.188276\tval-merror:0.506494\n",
      "[25]\ttrain-merror:0.181634\tval-merror:0.524675\n",
      "[26]\ttrain-merror:0.174126\tval-merror:0.519481\n",
      "[27]\ttrain-merror:0.162576\tval-merror:0.516883\n",
      "[28]\ttrain-merror:0.155357\tval-merror:0.490909\n",
      "[29]\ttrain-merror:0.150736\tval-merror:0.522078\n",
      "[30]\ttrain-merror:0.141207\tval-merror:0.498701\n",
      "[31]\ttrain-merror:0.141207\tval-merror:0.503896\n",
      "[32]\ttrain-merror:0.138031\tval-merror:0.516883\n",
      "[33]\ttrain-merror:0.1311\tval-merror:0.514286\n",
      "[34]\ttrain-merror:0.127924\tval-merror:0.524675\n",
      "[35]\ttrain-merror:0.124459\tval-merror:0.511688\n",
      "[36]\ttrain-merror:0.120416\tval-merror:0.519481\n",
      "[37]\ttrain-merror:0.115218\tval-merror:0.514286\n",
      "[38]\ttrain-merror:0.113197\tval-merror:0.503896\n",
      "[39]\ttrain-merror:0.106555\tval-merror:0.509091\n",
      "[40]\ttrain-merror:0.102801\tval-merror:0.503896\n",
      "[41]\ttrain-merror:0.098181\tval-merror:0.514286\n",
      "[42]\ttrain-merror:0.094716\tval-merror:0.503896\n",
      "[43]\ttrain-merror:0.092983\tval-merror:0.506494\n",
      "[44]\ttrain-merror:0.089518\tval-merror:0.514286\n",
      "[45]\ttrain-merror:0.086919\tval-merror:0.519481\n",
      "[46]\ttrain-merror:0.082587\tval-merror:0.503896\n",
      "[47]\ttrain-merror:0.0797\tval-merror:0.516883\n",
      "[48]\ttrain-merror:0.077967\tval-merror:0.532468\n",
      "[49]\ttrain-merror:0.075946\tval-merror:0.527273\n",
      "[50]\ttrain-merror:0.073058\tval-merror:0.52987\n",
      "[51]\ttrain-merror:0.071903\tval-merror:0.535065\n",
      "[52]\ttrain-merror:0.068149\tval-merror:0.516883\n",
      "[53]\ttrain-merror:0.066705\tval-merror:0.519481\n",
      "[54]\ttrain-merror:0.063818\tval-merror:0.511688\n",
      "[55]\ttrain-merror:0.064973\tval-merror:0.522078\n",
      "[56]\ttrain-merror:0.061796\tval-merror:0.524675\n",
      "[57]\ttrain-merror:0.060064\tval-merror:0.52987\n",
      "[58]\ttrain-merror:0.057753\tval-merror:0.532468\n",
      "[59]\ttrain-merror:0.053711\tval-merror:0.532468\n",
      "[60]\ttrain-merror:0.050823\tval-merror:0.532468\n",
      "[61]\ttrain-merror:0.049957\tval-merror:0.527273\n",
      "[62]\ttrain-merror:0.047647\tval-merror:0.516883\n",
      "[63]\ttrain-merror:0.046203\tval-merror:0.514286\n",
      "[64]\ttrain-merror:0.045048\tval-merror:0.516883\n",
      "[65]\ttrain-merror:0.042738\tval-merror:0.511688\n",
      "[66]\ttrain-merror:0.04216\tval-merror:0.524675\n",
      "[67]\ttrain-merror:0.040427\tval-merror:0.52987\n",
      "[68]\ttrain-merror:0.038117\tval-merror:0.524675\n",
      "[69]\ttrain-merror:0.037828\tval-merror:0.532468\n",
      "[70]\ttrain-merror:0.036096\tval-merror:0.522078\n",
      "[71]\ttrain-merror:0.034075\tval-merror:0.52987\n",
      "[72]\ttrain-merror:0.031764\tval-merror:0.532468\n",
      "[73]\ttrain-merror:0.032053\tval-merror:0.52987\n",
      "[74]\ttrain-merror:0.029743\tval-merror:0.522078\n",
      "[75]\ttrain-merror:0.028299\tval-merror:0.524675\n",
      "[76]\ttrain-merror:0.028588\tval-merror:0.52987\n",
      "[77]\ttrain-merror:0.028588\tval-merror:0.524675\n",
      "[78]\ttrain-merror:0.028588\tval-merror:0.516883\n",
      "[79]\ttrain-merror:0.025989\tval-merror:0.524675\n",
      "[80]\ttrain-merror:0.0257\tval-merror:0.514286\n",
      "[81]\ttrain-merror:0.027144\tval-merror:0.519481\n",
      "[82]\ttrain-merror:0.024545\tval-merror:0.519481\n",
      "[83]\ttrain-merror:0.024545\tval-merror:0.519481\n",
      "[84]\ttrain-merror:0.024834\tval-merror:0.514286\n",
      "[85]\ttrain-merror:0.02339\tval-merror:0.516883\n",
      "[86]\ttrain-merror:0.023679\tval-merror:0.519481\n",
      "[87]\ttrain-merror:0.021946\tval-merror:0.516883\n",
      "[88]\ttrain-merror:0.023679\tval-merror:0.524675\n",
      "[89]\ttrain-merror:0.021658\tval-merror:0.527273\n",
      "[90]\ttrain-merror:0.02108\tval-merror:0.537662\n",
      "[91]\ttrain-merror:0.019347\tval-merror:0.527273\n",
      "[92]\ttrain-merror:0.01877\tval-merror:0.52987\n",
      "[93]\ttrain-merror:0.01877\tval-merror:0.527273\n",
      "[94]\ttrain-merror:0.017037\tval-merror:0.52987\n",
      "[95]\ttrain-merror:0.01646\tval-merror:0.524675\n",
      "[96]\ttrain-merror:0.016748\tval-merror:0.519481\n",
      "[97]\ttrain-merror:0.01646\tval-merror:0.514286\n",
      "[98]\ttrain-merror:0.015016\tval-merror:0.514286\n",
      "[99]\ttrain-merror:0.015016\tval-merror:0.509091\n",
      "[100]\ttrain-merror:0.014727\tval-merror:0.514286\n",
      "[101]\ttrain-merror:0.013861\tval-merror:0.516883\n",
      "[102]\ttrain-merror:0.013283\tval-merror:0.516883\n",
      "[103]\ttrain-merror:0.012995\tval-merror:0.509091\n",
      "[104]\ttrain-merror:0.011551\tval-merror:0.506494\n",
      "[105]\ttrain-merror:0.010684\tval-merror:0.511688\n",
      "[106]\ttrain-merror:0.011551\tval-merror:0.511688\n",
      "[107]\ttrain-merror:0.010973\tval-merror:0.503896\n",
      "[108]\ttrain-merror:0.010973\tval-merror:0.501299\n",
      "[109]\ttrain-merror:0.011262\tval-merror:0.503896\n",
      "[110]\ttrain-merror:0.009818\tval-merror:0.506494\n",
      "[111]\ttrain-merror:0.009818\tval-merror:0.498701\n",
      "[112]\ttrain-merror:0.010396\tval-merror:0.506494\n",
      "[113]\ttrain-merror:0.008952\tval-merror:0.501299\n",
      "[114]\ttrain-merror:0.008663\tval-merror:0.509091\n",
      "[115]\ttrain-merror:0.008663\tval-merror:0.509091\n",
      "[116]\ttrain-merror:0.008374\tval-merror:0.509091\n",
      "[117]\ttrain-merror:0.008374\tval-merror:0.511688\n",
      "[118]\ttrain-merror:0.007797\tval-merror:0.509091\n",
      "[119]\ttrain-merror:0.007508\tval-merror:0.511688\n",
      "[120]\ttrain-merror:0.007219\tval-merror:0.514286\n",
      "[121]\ttrain-merror:0.006642\tval-merror:0.514286\n",
      "[122]\ttrain-merror:0.005775\tval-merror:0.522078\n",
      "[123]\ttrain-merror:0.005775\tval-merror:0.519481\n",
      "[124]\ttrain-merror:0.005775\tval-merror:0.511688\n",
      "[125]\ttrain-merror:0.005775\tval-merror:0.506494\n",
      "[126]\ttrain-merror:0.005775\tval-merror:0.503896\n",
      "[127]\ttrain-merror:0.005487\tval-merror:0.514286\n",
      "[128]\ttrain-merror:0.005487\tval-merror:0.511688\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-merror:0.155357\tval-merror:0.490909\n",
      "\n",
      "end... \n",
      " cost time 5.40054988861084 (s)...\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "# 超参数\n",
    "paras={\n",
    "    'booster':'gbtree',\n",
    "    'objective':'multi:softmax', # 多分类问题，采用multisoft多分类器\n",
    "    'num_class':4, # 类别数，与multi softmax并用\n",
    "    'gamma':0.015, # 树的叶子节点下一个区分的最小损失\n",
    "    'max_depth':20, # 树的最大深度\n",
    "    'lambda':40, # L2正则项权重\n",
    "    'subsample':0.6, # 用于训练模型的子样本占整个样本集合的比例\n",
    "    'colsample_bytree':0.7, # 在建立树时对特征采样的比例\n",
    "    'min_child_weight':22, # 节点的最少特征数\n",
    "    'silent':1,\n",
    "    'eta':0.5, # 为了防止过拟合，更新过程中用到的收缩步\n",
    "    'seed':123,\n",
    "    'nthread':4, # cpu线程数\n",
    "}\n",
    "# 将上述所有超参数放到集合plst中\n",
    "plst=list(paras.items())\n",
    "\n",
    "# 将训练集划分为训练集（90%）和验证集（10%）\n",
    "X_train,x_val,Y_train,y_val = train_test_split(feature,label,test_size=0.1,random_state=156)\n",
    "\n",
    "# 设定总迭代次数\n",
    "num_rounds=5000\n",
    "\n",
    "# 置入DMatrix数据结构\n",
    "xgtrain=xgb.DMatrix(X_train, label=Y_train)#将训练集的二维数组加入到里面\n",
    "xgval=xgb.DMatrix(x_val,label=y_val)#将验证集的二维数组形式的数据加入到DMatrix对象中\n",
    "xgtest=xgb.DMatrix(test_data)\n",
    "\n",
    "# 设定观察训练集和验证集上的错误率\n",
    "watchlist =[(xgtrain,'train'),(xgval,'val')]\n",
    "\n",
    "# 训练 XGBoost 模型\n",
    "model = xgb.train(plst,xgtrain,num_rounds,watchlist,early_stopping_rounds=100)\n",
    "\n",
    "# 计算训练用时\n",
    "cost_time=time.time()-now\n",
    "print(\"end...\",'\\n',\"cost time\",cost_time,\"(s)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save The Model\n",
    "将训练得到的模型文件保存在 ```Model``` 目录下，模型文件名为 ```XGB.pickle.dat```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "pickle.dump(model, open(\"Model/XGB.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction\n",
    "基于得到的 XGBoost 模型对测试数据集进行预测，预测结果保存在 ```Output``` 目录下，预测结果文件名为 ```xgb_result.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "model = pickle.load(open(\"Model/XGB.pickle.dat\", \"rb\"))\n",
    "# 进行预测\n",
    "preds=model.predict(xgtest,ntree_limit=model.best_iteration) + 1 # +1 是为了将 label 改回从1开始标记\n",
    "np.savetxt('Output/xgb_result.csv',np.c_[range(1,len(test_data)+1),preds],\n",
    "           delimiter=',',header='id,label',comments='',fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
