{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "* 此 notebook 用于训练 XGBoost 模型，模型结果保存在 ```Model``` 目录下\n",
    "* 运行此 notebook 前，请确保已经正确运行前置程序 ```trainPrep.py```，得到特征文件 ```train_data.csv```，并确保它们和此程序位于同一目录下\n",
    "\n",
    "## 1. Preparation\n",
    "导入需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 取消warning\n",
    "\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data & Standardization\n",
    "读取数据，并使用 z-score 进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_ = pd.read_csv('train_data.csv')\n",
    "# 填充缺失值\n",
    "train_ = train_.fillna(0)\n",
    "# 定义标准化函数\n",
    "def standardization(df):\n",
    "    newDataFrame = pd.DataFrame(index=df.index)\n",
    "    columns = df.columns.tolist()\n",
    "    for c in columns:\n",
    "        if (c == 'label'):\n",
    "            newDataFrame[c] = df[c].tolist()\n",
    "        else:\n",
    "            d = df[c]\n",
    "            newDataFrame[c] = ((d - np.mean(d)) / (np.std(d))).tolist()\n",
    "    return newDataFrame\n",
    "# 进行标准化\n",
    "train_data = standardization(train_)\n",
    "# 提取特征和类别\n",
    "label = train_data['label'] # label 从 0 开始标记，0，1，2，3 分别表示 4 种情绪\n",
    "feature = train_data.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "训练 XGBoost 模型，并调整超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.546347\tval-merror:0.605195\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.493214\tval-merror:0.579221\n",
      "[2]\ttrain-merror:0.464915\tval-merror:0.592208\n",
      "[3]\ttrain-merror:0.436616\tval-merror:0.592208\n",
      "[4]\ttrain-merror:0.41207\tval-merror:0.574026\n",
      "[5]\ttrain-merror:0.402252\tval-merror:0.563636\n",
      "[6]\ttrain-merror:0.375975\tval-merror:0.535065\n",
      "[7]\ttrain-merror:0.359226\tval-merror:0.563636\n",
      "[8]\ttrain-merror:0.338435\tval-merror:0.563636\n",
      "[9]\ttrain-merror:0.322841\tval-merror:0.563636\n",
      "[10]\ttrain-merror:0.309269\tval-merror:0.558442\n",
      "[11]\ttrain-merror:0.304649\tval-merror:0.548052\n",
      "[12]\ttrain-merror:0.293965\tval-merror:0.568831\n",
      "[13]\ttrain-merror:0.286168\tval-merror:0.550649\n",
      "[14]\ttrain-merror:0.263355\tval-merror:0.550649\n",
      "[15]\ttrain-merror:0.258158\tval-merror:0.550649\n",
      "[16]\ttrain-merror:0.255848\tval-merror:0.542857\n",
      "[17]\ttrain-merror:0.241409\tval-merror:0.548052\n",
      "[18]\ttrain-merror:0.230147\tval-merror:0.527273\n",
      "[19]\ttrain-merror:0.231014\tval-merror:0.545455\n",
      "[20]\ttrain-merror:0.218019\tval-merror:0.54026\n",
      "[21]\ttrain-merror:0.209645\tval-merror:0.545455\n",
      "[22]\ttrain-merror:0.205025\tval-merror:0.545455\n",
      "[23]\ttrain-merror:0.193763\tval-merror:0.548052\n",
      "[24]\ttrain-merror:0.190297\tval-merror:0.548052\n",
      "[25]\ttrain-merror:0.175859\tval-merror:0.550649\n",
      "[26]\ttrain-merror:0.163731\tval-merror:0.532468\n",
      "[27]\ttrain-merror:0.159688\tval-merror:0.54026\n",
      "[28]\ttrain-merror:0.159399\tval-merror:0.537662\n",
      "[29]\ttrain-merror:0.152758\tval-merror:0.535065\n",
      "[30]\ttrain-merror:0.14756\tval-merror:0.535065\n",
      "[31]\ttrain-merror:0.144095\tval-merror:0.548052\n",
      "[32]\ttrain-merror:0.143228\tval-merror:0.54026\n",
      "[33]\ttrain-merror:0.14063\tval-merror:0.537662\n",
      "[34]\ttrain-merror:0.131967\tval-merror:0.537662\n",
      "[35]\ttrain-merror:0.12648\tval-merror:0.54026\n",
      "[36]\ttrain-merror:0.124747\tval-merror:0.54026\n",
      "[37]\ttrain-merror:0.120127\tval-merror:0.535065\n",
      "[38]\ttrain-merror:0.116084\tval-merror:0.524675\n",
      "[39]\ttrain-merror:0.109443\tval-merror:0.532468\n",
      "[40]\ttrain-merror:0.108865\tval-merror:0.52987\n",
      "[41]\ttrain-merror:0.10771\tval-merror:0.535065\n",
      "[42]\ttrain-merror:0.099913\tval-merror:0.527273\n",
      "[43]\ttrain-merror:0.095293\tval-merror:0.532468\n",
      "[44]\ttrain-merror:0.090673\tval-merror:0.54026\n",
      "[45]\ttrain-merror:0.091539\tval-merror:0.54026\n",
      "[46]\ttrain-merror:0.089229\tval-merror:0.52987\n",
      "[47]\ttrain-merror:0.088363\tval-merror:0.527273\n",
      "[48]\ttrain-merror:0.086919\tval-merror:0.519481\n",
      "[49]\ttrain-merror:0.082299\tval-merror:0.516883\n",
      "[50]\ttrain-merror:0.080566\tval-merror:0.514286\n",
      "[51]\ttrain-merror:0.077967\tval-merror:0.511688\n",
      "[52]\ttrain-merror:0.075079\tval-merror:0.501299\n",
      "[53]\ttrain-merror:0.071037\tval-merror:0.506494\n",
      "[54]\ttrain-merror:0.069882\tval-merror:0.514286\n",
      "[55]\ttrain-merror:0.067571\tval-merror:0.509091\n",
      "[56]\ttrain-merror:0.065261\tval-merror:0.514286\n",
      "[57]\ttrain-merror:0.059775\tval-merror:0.516883\n",
      "[58]\ttrain-merror:0.058042\tval-merror:0.516883\n",
      "[59]\ttrain-merror:0.057465\tval-merror:0.511688\n",
      "[60]\ttrain-merror:0.052556\tval-merror:0.511688\n",
      "[61]\ttrain-merror:0.052844\tval-merror:0.514286\n",
      "[62]\ttrain-merror:0.050534\tval-merror:0.519481\n",
      "[63]\ttrain-merror:0.048224\tval-merror:0.522078\n",
      "[64]\ttrain-merror:0.045336\tval-merror:0.506494\n",
      "[65]\ttrain-merror:0.045625\tval-merror:0.516883\n",
      "[66]\ttrain-merror:0.041582\tval-merror:0.535065\n",
      "[67]\ttrain-merror:0.040139\tval-merror:0.524675\n",
      "[68]\ttrain-merror:0.041005\tval-merror:0.514286\n",
      "[69]\ttrain-merror:0.03985\tval-merror:0.516883\n",
      "[70]\ttrain-merror:0.036673\tval-merror:0.519481\n",
      "[71]\ttrain-merror:0.033497\tval-merror:0.514286\n",
      "[72]\ttrain-merror:0.032342\tval-merror:0.511688\n",
      "[73]\ttrain-merror:0.031476\tval-merror:0.516883\n",
      "[74]\ttrain-merror:0.029743\tval-merror:0.506494\n",
      "[75]\ttrain-merror:0.029165\tval-merror:0.506494\n",
      "[76]\ttrain-merror:0.026278\tval-merror:0.514286\n",
      "[77]\ttrain-merror:0.0257\tval-merror:0.511688\n",
      "[78]\ttrain-merror:0.024256\tval-merror:0.511688\n",
      "[79]\ttrain-merror:0.023101\tval-merror:0.511688\n",
      "[80]\ttrain-merror:0.02108\tval-merror:0.514286\n",
      "[81]\ttrain-merror:0.020214\tval-merror:0.527273\n",
      "[82]\ttrain-merror:0.019925\tval-merror:0.514286\n",
      "[83]\ttrain-merror:0.018192\tval-merror:0.506494\n",
      "[84]\ttrain-merror:0.017037\tval-merror:0.511688\n",
      "[85]\ttrain-merror:0.017904\tval-merror:0.511688\n",
      "[86]\ttrain-merror:0.016171\tval-merror:0.514286\n",
      "[87]\ttrain-merror:0.01646\tval-merror:0.514286\n",
      "[88]\ttrain-merror:0.016171\tval-merror:0.514286\n",
      "[89]\ttrain-merror:0.015882\tval-merror:0.519481\n",
      "[90]\ttrain-merror:0.013861\tval-merror:0.524675\n",
      "[91]\ttrain-merror:0.012995\tval-merror:0.522078\n",
      "[92]\ttrain-merror:0.012995\tval-merror:0.527273\n",
      "[93]\ttrain-merror:0.012706\tval-merror:0.527273\n",
      "[94]\ttrain-merror:0.012706\tval-merror:0.522078\n",
      "[95]\ttrain-merror:0.012417\tval-merror:0.516883\n",
      "[96]\ttrain-merror:0.011839\tval-merror:0.511688\n",
      "[97]\ttrain-merror:0.011262\tval-merror:0.514286\n",
      "[98]\ttrain-merror:0.010684\tval-merror:0.511688\n",
      "[99]\ttrain-merror:0.009529\tval-merror:0.522078\n",
      "[100]\ttrain-merror:0.008663\tval-merror:0.522078\n",
      "[101]\ttrain-merror:0.008952\tval-merror:0.516883\n",
      "[102]\ttrain-merror:0.009529\tval-merror:0.522078\n",
      "[103]\ttrain-merror:0.009241\tval-merror:0.522078\n",
      "[104]\ttrain-merror:0.009241\tval-merror:0.511688\n",
      "[105]\ttrain-merror:0.008952\tval-merror:0.511688\n",
      "[106]\ttrain-merror:0.009241\tval-merror:0.514286\n",
      "[107]\ttrain-merror:0.008374\tval-merror:0.509091\n",
      "[108]\ttrain-merror:0.008085\tval-merror:0.514286\n",
      "[109]\ttrain-merror:0.007508\tval-merror:0.514286\n",
      "[110]\ttrain-merror:0.007797\tval-merror:0.509091\n",
      "[111]\ttrain-merror:0.008085\tval-merror:0.509091\n",
      "[112]\ttrain-merror:0.007219\tval-merror:0.511688\n",
      "[113]\ttrain-merror:0.006064\tval-merror:0.514286\n",
      "[114]\ttrain-merror:0.006064\tval-merror:0.506494\n",
      "[115]\ttrain-merror:0.006642\tval-merror:0.511688\n",
      "[116]\ttrain-merror:0.008085\tval-merror:0.509091\n",
      "[117]\ttrain-merror:0.007508\tval-merror:0.511688\n",
      "[118]\ttrain-merror:0.00693\tval-merror:0.506494\n",
      "[119]\ttrain-merror:0.007219\tval-merror:0.503896\n",
      "[120]\ttrain-merror:0.006642\tval-merror:0.493506\n",
      "[121]\ttrain-merror:0.006064\tval-merror:0.503896\n",
      "[122]\ttrain-merror:0.006064\tval-merror:0.501299\n",
      "[123]\ttrain-merror:0.005775\tval-merror:0.503896\n",
      "[124]\ttrain-merror:0.005487\tval-merror:0.509091\n",
      "[125]\ttrain-merror:0.00462\tval-merror:0.503896\n",
      "[126]\ttrain-merror:0.004332\tval-merror:0.503896\n",
      "[127]\ttrain-merror:0.00462\tval-merror:0.506494\n",
      "[128]\ttrain-merror:0.00462\tval-merror:0.501299\n",
      "[129]\ttrain-merror:0.004043\tval-merror:0.501299\n",
      "[130]\ttrain-merror:0.004332\tval-merror:0.506494\n",
      "[131]\ttrain-merror:0.004043\tval-merror:0.506494\n",
      "[132]\ttrain-merror:0.003465\tval-merror:0.501299\n",
      "[133]\ttrain-merror:0.003465\tval-merror:0.503896\n",
      "[134]\ttrain-merror:0.003176\tval-merror:0.501299\n",
      "[135]\ttrain-merror:0.002888\tval-merror:0.501299\n",
      "[136]\ttrain-merror:0.002888\tval-merror:0.501299\n",
      "[137]\ttrain-merror:0.002888\tval-merror:0.496104\n",
      "[138]\ttrain-merror:0.003176\tval-merror:0.501299\n",
      "[139]\ttrain-merror:0.002888\tval-merror:0.503896\n",
      "[140]\ttrain-merror:0.003465\tval-merror:0.509091\n",
      "[141]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[142]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[143]\ttrain-merror:0.002888\tval-merror:0.506494\n",
      "[144]\ttrain-merror:0.002599\tval-merror:0.509091\n",
      "[145]\ttrain-merror:0.002599\tval-merror:0.511688\n",
      "[146]\ttrain-merror:0.002599\tval-merror:0.511688\n",
      "[147]\ttrain-merror:0.002599\tval-merror:0.514286\n",
      "[148]\ttrain-merror:0.002599\tval-merror:0.506494\n",
      "[149]\ttrain-merror:0.002599\tval-merror:0.506494\n",
      "[150]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[151]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[152]\ttrain-merror:0.002888\tval-merror:0.503896\n",
      "[153]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[154]\ttrain-merror:0.002888\tval-merror:0.509091\n",
      "[155]\ttrain-merror:0.003465\tval-merror:0.509091\n",
      "[156]\ttrain-merror:0.003176\tval-merror:0.503896\n",
      "[157]\ttrain-merror:0.003176\tval-merror:0.509091\n",
      "[158]\ttrain-merror:0.002888\tval-merror:0.503896\n",
      "[159]\ttrain-merror:0.002888\tval-merror:0.503896\n",
      "[160]\ttrain-merror:0.00231\tval-merror:0.506494\n",
      "[161]\ttrain-merror:0.00231\tval-merror:0.501299\n",
      "[162]\ttrain-merror:0.00231\tval-merror:0.503896\n",
      "[163]\ttrain-merror:0.00231\tval-merror:0.509091\n",
      "[164]\ttrain-merror:0.002888\tval-merror:0.511688\n",
      "[165]\ttrain-merror:0.002888\tval-merror:0.511688\n",
      "[166]\ttrain-merror:0.002888\tval-merror:0.511688\n",
      "[167]\ttrain-merror:0.002599\tval-merror:0.509091\n",
      "[168]\ttrain-merror:0.00231\tval-merror:0.506494\n",
      "[169]\ttrain-merror:0.002021\tval-merror:0.503896\n",
      "[170]\ttrain-merror:0.00231\tval-merror:0.503896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\ttrain-merror:0.002021\tval-merror:0.509091\n",
      "[172]\ttrain-merror:0.00231\tval-merror:0.506494\n",
      "[173]\ttrain-merror:0.00231\tval-merror:0.503896\n",
      "[174]\ttrain-merror:0.00231\tval-merror:0.501299\n",
      "[175]\ttrain-merror:0.00231\tval-merror:0.503896\n",
      "[176]\ttrain-merror:0.00231\tval-merror:0.503896\n",
      "[177]\ttrain-merror:0.00231\tval-merror:0.509091\n",
      "[178]\ttrain-merror:0.00231\tval-merror:0.506494\n",
      "[179]\ttrain-merror:0.002021\tval-merror:0.511688\n",
      "[180]\ttrain-merror:0.002021\tval-merror:0.509091\n",
      "[181]\ttrain-merror:0.00231\tval-merror:0.511688\n",
      "[182]\ttrain-merror:0.002021\tval-merror:0.503896\n",
      "[183]\ttrain-merror:0.00231\tval-merror:0.509091\n",
      "[184]\ttrain-merror:0.001733\tval-merror:0.506494\n",
      "[185]\ttrain-merror:0.002021\tval-merror:0.506494\n",
      "[186]\ttrain-merror:0.002021\tval-merror:0.511688\n",
      "[187]\ttrain-merror:0.002021\tval-merror:0.511688\n",
      "[188]\ttrain-merror:0.001733\tval-merror:0.509091\n",
      "[189]\ttrain-merror:0.001733\tval-merror:0.511688\n",
      "[190]\ttrain-merror:0.001733\tval-merror:0.514286\n",
      "[191]\ttrain-merror:0.001733\tval-merror:0.519481\n",
      "[192]\ttrain-merror:0.001444\tval-merror:0.519481\n",
      "[193]\ttrain-merror:0.001444\tval-merror:0.516883\n",
      "[194]\ttrain-merror:0.001444\tval-merror:0.516883\n",
      "[195]\ttrain-merror:0.001155\tval-merror:0.516883\n",
      "[196]\ttrain-merror:0.001155\tval-merror:0.514286\n",
      "[197]\ttrain-merror:0.001444\tval-merror:0.514286\n",
      "[198]\ttrain-merror:0.001444\tval-merror:0.514286\n",
      "[199]\ttrain-merror:0.001155\tval-merror:0.516883\n",
      "[200]\ttrain-merror:0.001155\tval-merror:0.519481\n",
      "[201]\ttrain-merror:0.001155\tval-merror:0.519481\n",
      "[202]\ttrain-merror:0.001155\tval-merror:0.516883\n",
      "[203]\ttrain-merror:0.001155\tval-merror:0.516883\n",
      "[204]\ttrain-merror:0.000578\tval-merror:0.511688\n",
      "[205]\ttrain-merror:0.000866\tval-merror:0.511688\n",
      "[206]\ttrain-merror:0.000866\tval-merror:0.511688\n",
      "[207]\ttrain-merror:0.000866\tval-merror:0.511688\n",
      "[208]\ttrain-merror:0.001155\tval-merror:0.511688\n",
      "[209]\ttrain-merror:0.001155\tval-merror:0.511688\n",
      "[210]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[211]\ttrain-merror:0.000866\tval-merror:0.503896\n",
      "[212]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[213]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[214]\ttrain-merror:0.000866\tval-merror:0.503896\n",
      "[215]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[216]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[217]\ttrain-merror:0.000866\tval-merror:0.509091\n",
      "[218]\ttrain-merror:0.000866\tval-merror:0.506494\n",
      "[219]\ttrain-merror:0.000866\tval-merror:0.511688\n",
      "[220]\ttrain-merror:0.000866\tval-merror:0.511688\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-merror:0.006642\tval-merror:0.493506\n",
      "\n",
      "end... \n",
      " cost time 8.646825075149536 (s)...\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "# 超参数\n",
    "paras={\n",
    "    'booster':'gbtree',\n",
    "    'objective':'multi:softmax', # 多分类问题，采用multisoft多分类器\n",
    "    'num_class':4, # 类别数，与multi softmax并用\n",
    "    'gamma':0.015, # 树的叶子节点下一个区分的最小损失\n",
    "    'max_depth':20, # 树的最大深度\n",
    "    'lambda':40, # L2正则项权重\n",
    "    'subsample':0.6, # 用于训练模型的子样本占整个样本集合的比例\n",
    "    'colsample_bytree':0.7, # 在建立树时对特征采样的比例\n",
    "    'min_child_weight':22, # 节点的最少特征数\n",
    "    'silent':1,\n",
    "    'eta':0.5, # 为了防止过拟合，更新过程中用到的收缩步\n",
    "    'seed':123,\n",
    "    'nthread':4, # cpu线程数\n",
    "}\n",
    "# 将上述所有超参数放到集合plst中\n",
    "plst=list(paras.items())\n",
    "\n",
    "# 将训练集划分为训练集（90%）和验证集（10%）\n",
    "X_train,x_val,Y_train,y_val = train_test_split(feature,label,test_size=0.1,random_state=156)\n",
    "\n",
    "# 设定总迭代次数\n",
    "num_rounds=5000\n",
    "\n",
    "# 置入DMatrix数据结构\n",
    "xgtrain=xgb.DMatrix(X_train, label=Y_train)#将训练集的二维数组加入到里面\n",
    "xgval=xgb.DMatrix(x_val,label=y_val)#将验证集的二维数组形式的数据加入到DMatrix对象中\n",
    "\n",
    "# 设定观察训练集和验证集上的错误率\n",
    "watchlist =[(xgtrain,'train'),(xgval,'val')]\n",
    "\n",
    "# 训练 XGBoost 模型\n",
    "model = xgb.train(plst,xgtrain,num_rounds,watchlist,early_stopping_rounds=100)\n",
    "\n",
    "# 计算训练用时\n",
    "cost_time=time.time()-now\n",
    "print(\"end...\",'\\n',\"cost time\",cost_time,\"(s)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save The Model\n",
    "将训练得到的模型文件保存在 ```Model``` 目录下，模型文件名为 ```XGB.pickle.dat```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "pickle.dump(model, open(\"Model/XGB.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
